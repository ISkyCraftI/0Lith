# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Repository Layout

The git root is `C:\Users\skycr\Perso\0Lith\`. The actual application lives in `0lith-desktop/`. There is a detailed `0lith-desktop/CLAUDE.md` â€” read it for in-depth architecture, gotchas, and design rules.

```
0Lith/
â”œâ”€â”€ 0lith-desktop/      # Tauri 2 + Svelte 5 + Python desktop app
â”‚   â”œâ”€â”€ src/            # Svelte 5 frontend
â”‚   â”œâ”€â”€ src-tauri/      # Rust/Tauri 2 shell + capabilities
â”‚   â””â”€â”€ py-backend/     # Python 3.12 multi-agent backend
â””â”€â”€ Reflexions/         # Research docs, market analysis, strategy
```

## Common Commands

All commands run from `0lith-desktop/` unless noted.

```bash
# Full dev â€” standard (no WDAC/HVCI restriction)
npm run tauri dev

# Full dev â€” WDAC/HVCI machine (Memory Integrity ON, signs binary after each Rust build)
# Terminal 1:
npm run dev                    # Vite HMR only
# Terminal 2 (PowerShell, from 0lith-desktop/):
.\scripts\dev-sign.ps1         # cargo build + sign + launch exe

# Production build
npm run tauri build

# TypeScript/Svelte type check
npm run check

# Python deps
pip install -r py-backend/requirements.txt

# External services (must be running before dev)
docker start qdrant        # Qdrant vector DB on :6333 â€” pending migration to embedded mode
docker start pyrolith      # Pyrolith LLM on :11435 â€” pending Docker security hardening

# Memory management
python py-backend/olith_memory_init.py          # Init
python py-backend/olith_memory_init.py --test   # Verify
python py-backend/olith_memory_init.py --reset  # Wipe + re-init
```

## Architecture Summary

**Stack**: Tauri 2 Â· Svelte 5 runes Â· TypeScript Â· Python 3.12 Â· TailwindCSS 4

**IPC**: Two persistent Python processes are spawned at startup via `tauri-plugin-shell`:
- `olith_core.py` â€” reactive chat backend (command router â†’ agent system â†’ Ollama)
- `olith_watcher.py` â€” proactive background loop (file watcher, suggestions)

Both communicate via **JSON line-delimited stdin/stdout** with UUID-correlated requests/responses. The Tauri process CWD is `src-tauri/`, so shell spawn paths use `../py-backend/`.

**Agent routing**: Every user message hits `Hodolith` (qwen3:1.7b) first for classification, then routes to one of: Monolith (14b general), Aerolith (30b coder), Cryolith (8b blue team), Pyrolith (7b red team via Docker).

**Memory**: Mem0 + Qdrant (currently Docker, pending migration to embedded `QdrantClient(path=...)`) + optional Kuzu (graph). Embeddings: qwen3-embedding:0.6b (1024 dims, code-aware, #1 MTEB Multilingual). MemOS v2.0 flagged for Phase 2 evaluation (Tool Memory, KV-cache injection).

**Key rules** (from `0lith-desktop/CLAUDE.md`):
- Python must be **3.12** (not 3.13+) â€” Kuzu requirement
- Svelte **5 runes only** â€” `$state`, `$derived`, `$effect` (no Svelte 4 `writable()`)
- **Tauri 2** â€” shell permissions live in `src-tauri/capabilities/default.json`
- qwen3 models emit `<think>...</think>` blocks â€” strip before parsing JSON routing responses
- Gaming Mode unloads all models from VRAM; 0Lith must never monopolize the RTX 5070 Ti
- `.claude/` and `__pycache__/` are in `.gitignore` âœ“ â€” verified

## Immediate Sprint Priorities

From `Reflexions/Matrice Einsenhower.md` â€” ranked by urgency and impact:

### This Week (Urgent + Important)
1. ~~**Repo cleanup**: fix `.gitignore` (remove `__pycache__`, `.obsidian` from tracking), clean cached files~~ **DONE** â€” gitignore enhanced, Reflexions/ staged, root CLAUDE.md committed
2. ~~**English README**: pitch, demo GIF, hardware requirements, 5-step quickstart, roadmap~~ **DONE** â€” README.md rewritten in English, README.fr.md kept as French copy (with ðŸ‡«ðŸ‡·/ðŸ‡¬ðŸ‡§ links)
3. ~~**AGPL-3.0 license**: add LICENSE file~~ **DONE** â€” LICENSE added at root
4. ~~**One working end-to-end demo**: red team OR blue team flow~~ **DONE** â€” Arena v2: SQL Injection sparring (5 rounds, live streaming, score + review) + UX v2: scenario selector, round progress dots, Unicode badges, loading animation, winner badge, export log + robustesse: timeouts adaptatifs par modÃ¨le, fallback automatique qwen3:14b, sÃ©quences de types forcÃ©es, contexte rÃ©duit (max 2 rounds), session 30 min

### Next 2-4 Weeks (Important)
5. Demo video 2-3 min (key content for r/LocalLLaMA, HN)
6. Installer bundle (.exe/.dmg with Ollama + models + Qdrant + GUI)
7. GitHub topics, issue templates, Sponsors activation
8. r/LocalLLaMA launch post preparation

### Critical â€” Infrastructure & Security
1. **Qdrant embedded mode**: replace Docker with `QdrantClient(path="./qdrant_data")` in `olith_memory_init.py` â€” removes `docker start qdrant` requirement entirely
2. **Pyrolith Docker hardening**: non-root user, `--cap-drop=ALL`, isolated bridge network, no outbound internet by default
3. **Shadow Thinking** â€” 2-3 days *(olith_watcher.py shadow loop exists; Mem0 pre-answer storage needs wiring to chat)*

### High â€” Next sprint
4. **Agent output JSON schema**: standardize structured responses to prevent frontend parse bugs
5. **Aerolith loading UI**: "Aerolith rÃ©flÃ©chitâ€¦ 3-5 min", progress bar, cancel â€” don't drop the 30B, make the wait dignified
6. **Hodolith routing clarity**: Monolith *plans/reasons about* code, Aerolith *writes* code â€” update routing prompt
7. Conversation deletion + multi-select â€” 0.5 day

### Medium â€” Month 2-3
8. Startup health checks (Ollama up? models pulled? Pyrolith container ready?)
9. Memory token budget (â‰¤ 512 tokens injected into small model contexts)
10. Monthly memory pruning (Monolith reviews Mem0 entries > 30 days)
11. Training Mode (Pyrolith vs Cryolith CVE sparring overnight + morning briefing)
12. Sidebar tabs (Agents / History) â€” 1 day
13. OLithEye animated SVG â€” 1-2 days
14. MCP Server for Zed.dev â€” 2-3 days
15. Agents enfichables YAML (dock architecture) â€” 2-3 days

## Business Context

**Positioning**: Only tool combining multi-agents + desktop GUI + 100% local + cybersecurity specialization. No competitor covers all four.

**License**: AGPL-3.0 (open-source, copyleft for commercial forks)

**Revenue model**: GitHub Sponsors + commercial AGPL license + B2B consulting (NIS2/DORA compliance deployment)

**Market**: On-device AI $20-30B (2025), cybersecurity AI $30.9B â†’ $86-104B by 2030. Regulatory tailwinds: NIS2 (Oct 2024), DORA (Jan 2025), EU AI Act.

**Window**: 18-36 months before Big Tech (Apple, Microsoft, Google) ships competitive local multi-agent desktop tools.

See `Reflexions/Etude de MarchÃ©.md` and `Reflexions/0Lith_et_marche_potentiel.md` for full analysis.

## Reflexions Reference

The `Reflexions/` folder contains research and strategy documentation:

| File | Content |
|------|---------|
| `0Lith_Memory_Architecture.md` | Full technical spec: Mem0 + Qdrant + Kuzu architecture, why NOT a Bibliolith LLM, multi-agent scoping, 5-level memory hierarchy |
| `0Lith_Embeddings_Memory_Research.md` | Embedding model comparison (Qwen3 vs Snowflake), MemOS/Memory-R1/Mem-Î± breakthroughs, phase roadmap |
| `Etude de MarchÃ©.md` | Market analysis ($30B cybersec AI), competitive landscape (25+ tools), regulatory tailwinds, business model, launch strategy |
| `Matrice Einsenhower.md` | Priority matrix for current sprint â€” repo cleanup, English README, AGPL, demo, launch prep |
| `IDEAS.md` | Full backlog with status tracking (same as root IDEAS.md, synced copy) |
| `Mission.md` | Original project charter with phase specs (same as root Mission.md, synced copy) |
| `idÃ©es de noms agents.md` | Agent naming conventions for future docks |

## Git specifiactions

Never push on Github by adding Claude or Claude Code as a coauthor. ISkyCraftI has to push alone.
