# OLith ‚Äî Recherche Approfondie : Embeddings & Syst√®mes de M√©moire Agent
## √âtat de l'art F√©vrier 2026

---

## 1. Snowflake Arctic Embed 2 vs Qwen3-Embedding : Le Verdict

### Snowflake Arctic Embed 2 (d√©cembre 2024)

| Propri√©t√© | Valeur |
|-----------|--------|
| **Param√®tres** | 113M (medium) / 303M (large) |
| **Dimensions** | 768 (medium) / 1024 (large), MRL ‚Üí 256 |
| **MTEB Retrieval** | 0.554 (medium) / bon (large) |
| **Langues** | Multilingue (EN + FR/ES/IT/DE focus) |
| **Contexte** | 8192 tokens |
| **VRAM** | ~250 Mo (medium) / ~700 Mo (large) |
| **Licence** | Apache 2.0 |
| **Date** | D√©cembre 2024 |
| **Sur Ollama** | `ollama pull snowflake-arctic-embed2` (568 Mo) |

**Points forts** : Ultra-l√©ger, tr√®s rapide (>100 docs/sec sur A10), excellente compressibilit√© MRL (3-4x avec <3% d√©gradation), bon pour l'anglais.

**Limites** : Date de 2024, pas de support instructions custom, pas de code retrieval optimis√©, couverture multilingue limit√©e (5-6 langues focus), pas de compr√©hension de langages de programmation.

---

### Qwen3-Embedding (mai 2025) ‚Äî **Le nouveau #1 mondial**

| Propri√©t√© | 0.6B | 4B | 8B |
|-----------|------|-----|-----|
| **MTEB Multilingual** | Bon | Tr√®s bon | **70.58 (#1 mondial)** |
| **Dimensions** | 32-1024 (MRL flexible) | 32-1024 | 32-1024 |
| **Langues** | 100+ langues + code | 100+ | 100+ |
| **Contexte** | 32 768 tokens | 32 768 | 32 768 |
| **VRAM estim√©** | ~400 Mo (FP16) / ~350 Mo (Q4) | ~2.5 Go (Q4) | ~5 Go (Q4) |
| **Licence** | Apache 2.0 | Apache 2.0 | Apache 2.0 |
| **Instructions** | ‚úÖ Oui (+1-5% perf) | ‚úÖ Oui | ‚úÖ Oui |
| **Code retrieval** | ‚úÖ Natif | ‚úÖ Natif | ‚úÖ Natif |
| **Sur Ollama** | `ollama pull qwen3-embedding:0.6b` | `qwen3-embedding:4b` | `qwen3-embedding` |

**Points forts** :
- **#1 mondial MTEB Multilingual** (score 70.58, juin 2025)
- **Instruction-aware** : tu peux personnaliser le comportement par t√¢che (ex: `Instruct: Given a cybersecurity vulnerability description, retrieve related exploits`)
- **Dimensions flexibles** : de 32 √† 1024 via MRL ‚Äî tu choisis le ratio qualit√©/stockage
- **Code retrieval natif** : comprend Python, Bash, exploits ‚Äî crucial pour OLith
- **100+ langues** : FR/EN bilingue natif + langages de programmation
- **Contexte 32K** : 4√ó plus long que Arctic Embed 2 ‚Äî peut embedder des rapports entiers
- **Famille Qwen3** : m√™me base que tes agents Monolith/Hodolith, synergie maximale

---

### Comparaison directe pour OLith

| Crit√®re | Arctic Embed 2 | Qwen3-Embedding 0.6B | **Recommand√©** |
|---------|---------------|----------------------|----------------|
| Qualit√© embeddings | Bonne | Sup√©rieure (+15-20%) | üèÜ Qwen3 |
| VRAM | ~250 Mo | ~350-400 Mo | ‚âà √âgal |
| Vitesse | Tr√®s rapide | Rapide | Arctic l√©g√®rement |
| Code/exploits | ‚ùå Non optimis√© | ‚úÖ Natif | üèÜ Qwen3 |
| Instructions custom | ‚ùå Non | ‚úÖ Oui (+5%) | üèÜ Qwen3 |
| Contexte max | 8K tokens | 32K tokens | üèÜ Qwen3 |
| Multilingual FR/EN | Limit√© | Excellent | üèÜ Qwen3 |
| Synergie OLith | Aucune | M√™me famille Qwen3 | üèÜ Qwen3 |
| Maturit√© | 14 mois | 9 mois | Arctic |
| Date | D√©c 2024 | Mai 2025 | Qwen3 plus r√©cent |

**üéØ Verdict : `qwen3-embedding:0.6b` est le choix optimal pour OLith.**

Raisons :
1. M√™me famille que tes LLM agents ‚Üí coh√©rence s√©mantique
2. Code retrieval natif ‚Üí indispensable pour exploits CVE, scripts pentest
3. Instructions custom ‚Üí tu peux dire "retrieve cybersecurity memories" et gagner 5%
4. 32K contexte ‚Üí peut embedder un rapport Nmap complet en un seul vecteur
5. VRAM raisonnable (~350 Mo) ‚Üí laisse de la place pour tes agents

**Commande :**
```bash
ollama pull qwen3-embedding:0.6b
```

**Configuration Mem0 mise √† jour :**
```python
"embedder": {
    "provider": "ollama",
    "config": {
        "model": "qwen3-embedding:0.6b",
        "ollama_base_url": "http://localhost:11434"
    }
}
```

> ‚ö†Ô∏è **Note importante** : Qwen3-Embedding utilise le **dernier token** comme `<|endoftext|>`. Ollama g√®re √ßa automatiquement, mais si tu utilises l'API directement, il faut l'ajouter manuellement. Les dimensions par d√©faut sont 1024, mais tu peux les r√©duire via MRL.

---

## 2. Les √âtudiants Chinois qui ont R√©volutionn√© la M√©moire Agent

Tu avais raison ‚Äî il y a eu deux perc√©es majeures par des √©quipes chinoises en 2025.

### 2A. MemOS ‚Äî "Memory Operating System" (Shanghai Jiao Tong + Zhejiang University)

**Paper** : arXiv:2507.03724 (juillet 2025)
**√âquipe** : Zhiyu Li, Shichao Song, Chenyang Xi et ~30 chercheurs
**Institutions** : MemTensor (Shanghai), Shanghai Jiao Tong University, Renmin University, China Telecom Research
**GitHub** : github.com/MemTensor/MemOS (4.4K+ ‚≠ê)
**Licence** : MIT (open-source)

#### Le concept r√©volutionnaire : la m√©moire comme ressource OS

MemOS traite la **m√©moire comme un citoyen de premi√®re classe** ‚Äî exactement comme un OS g√®re CPU et stockage. L√† o√π Mem0 fait du CRUD basique (add/search/update), MemOS introduit un syst√®me complet de gouvernance m√©moire.

#### Architecture 3 couches (inspir√©e d'un vrai OS)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Interface Layer (API Cortex)           ‚îÇ  ‚Üê Requ√™tes m√©moire read/write
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Operation Layer (MemScheduler)         ‚îÇ  ‚Üê D√©cide quoi activer/compresser/oublier
‚îÇ  ‚Ä¢ Next-Scene Prediction               ‚îÇ     (comme le prefrontal cortex)
‚îÇ  ‚Ä¢ Memory Fusion & Migration            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Infrastructure Layer (Storage)         ‚îÇ  ‚Üê Hot/Warm/Cold tiers
‚îÇ  ‚Ä¢ RAM-like (fr√©quent)                  ‚îÇ
‚îÇ  ‚Ä¢ SSD-like (sessions)                  ‚îÇ
‚îÇ  ‚Ä¢ Deep storage (archives)              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### MemCube ‚Äî L'abstraction unifi√©e

Le c≈ìur de MemOS est le **MemCube** : une unit√© m√©moire standardis√©e qui encapsule :

1. **Plaintext Memory** : connaissances textuelles (CVE, rapports, faits)
2. **Activation Memory** : KV-cache pour acc√©l√©rer l'inf√©rence (r√©utilisation de contexte)
3. **Parameter Memory** : poids LoRA, adaptations de mod√®le
4. **Tool Memory** (v2.0) : trajectoires d'appels d'outils pour am√©liorer le planning

Chaque MemCube contient :
- **Metadata** : timestamp, origine, type s√©mantique, version
- **Governance** : contr√¥le d'acc√®s, TTL (dur√©e de vie), priorit√©, tags de conformit√©
- **Behavioral metrics** : fr√©quence d'utilisation, pertinence, decay

#### Benchmarks : MemOS √©crase tout

| Benchmark | M√©trique | MemOS vs Mem0 | MemOS vs OpenAI Memory |
|-----------|----------|---------------|------------------------|
| LOCOMO (overall) | F1/BLEU | **+38.9%** | **+159% temporal reasoning** |
| Latence | p95 | Plus rapide | **-94% via KV-cache injection** |
| LoCoMo temporal | Temporal reasoning | Dominant | **+159%** |

MemOS surpasse : MIRIX, Mem0, Zep, Memobase, MemU, et Supermemory.

#### Versions et √©volution

| Version | Date | Nouveaut√©s |
|---------|------|------------|
| v1.0 Stellar (ÊòüÊ≤≥) | Juillet 2025 | Premier release, MemCube, plaintext + KV-cache |
| v1.0.0 MemCube | Ao√ªt 2025 | Word game demo, LongMemEval, NebulaGraph |
| v2.0 Stardust (ÊòüÂ∞ò) | D√©cembre 2025 | Knowledge base, multi-modal, Tool Memory, Redis Streams, MCP |

#### Compatibilit√© MemOS

- **LLM** : HuggingFace, OpenAI, **Ollama** ‚úÖ
- **Plateforme** : Linux (Windows/Mac en dev)
- **Installation** : `pip install MemoryOS`
- **D√©ploiement** : Docker + Redis Streams (v2.0) ou lightweight

---

### 2B. MemoryOS (EMNLP 2025 ‚Äî Beijing)

**Paper** : "Memory OS of AI Agent" ‚Äî EMNLP 2025 (Suzhou, Chine)
**Auteurs** : Jiazheng Kang, Mingming Ji, Zhe Zhao, Ting Bai
**R√©sultats** : +48.36% F1, +46.18% BLEU-1 sur LoCoMo

Architecture hi√©rarchique √† 3 niveaux :
- **Short-term** : dialogue courant (FIFO)
- **Mid-term** : cha√Ænes de dialogue r√©centes (segmented page organization)
- **Long-term** : m√©moire personnelle persistante

> Note : C'est un paper acad√©mique (pas d'impl√©mentation open-source aussi mature que MemOS).

---

### 2C. Memory-R1 (ao√ªt 2025 ‚Äî Munich/Cambridge/Hong Kong)

**Paper** : arXiv:2508.19828
**Concept** : Utiliser le **Reinforcement Learning** (PPO/GRPO) pour apprendre √† g√©rer la m√©moire

Deux agents sp√©cialis√©s :
1. **Memory Manager** : apprend quand ADD, UPDATE, DELETE, NOOP
2. **Answer Agent** : filtre et raisonne sur les m√©moires r√©cup√©r√©es (Memory Distillation)

**R√©sultats vs Mem0** : +57.3% F1, +41.5% BLEU-1, +33.8% LLM-as-Judge (sur Qwen-2.5-7B)

**Pourquoi c'est important** : Mem0 utilise des heuristiques cod√©es en dur pour d√©cider quoi stocker. Memory-R1 prouve qu'un agent peut **apprendre** √† mieux g√©rer sa m√©moire via RL ‚Äî les mises √† jour ne fragmentent plus la m√©moire.

---

### 2D. Mem-Œ± (septembre 2025) ‚Äî La suite logique

**Paper** : arXiv:2509.25911
**Concept** : M√™me approche RL que Memory-R1, mais pour des **architectures m√©moire complexes** (multi-composants : √©pisodique, s√©mantique, proc√©durale)

Critique de Memory-R1 : structures m√©moire trop simples (listes de faits). Mem-Œ± entra√Æne l'agent √† naviguer des syst√®mes m√©moire sophistiqu√©s avec diff√©rents types de m√©moire.

---

## 3. Impact sur la Stack OLith : Recommandation R√©vis√©e

### Constat : Mem0 reste le meilleur choix pragmatique pour OLith V1

Malgr√© les avanc√©es de MemOS et Memory-R1, voici pourquoi **Mem0 + Qdrant + Kuzu reste optimal** pour toi maintenant :

| Crit√®re | Mem0 | MemOS | Memory-R1 |
|---------|------|-------|-----------|
| **Maturit√© production** | ‚úÖ v1.0+, battle-tested | ‚ö†Ô∏è v2.0 r√©cent | ‚ùå Paper seulement |
| **Ollama natif** | ‚úÖ Support√© | ‚úÖ Support√© | ‚ùå Non |
| **Qdrant int√©gr√©** | ‚úÖ Natif | ‚ùå Pas directement | ‚ùå Non |
| **Kuzu int√©gr√©** | ‚úÖ Natif (v0.1.117) | ‚ùå NebulaGraph | ‚ùå Non |
| **Graph memory** | ‚úÖ Oui (Mem0g) | ‚úÖ Oui (hi√©rarchique) | ‚ùå Non |
| **Multi-agent scoping** | ‚úÖ agent_id/user_id | ‚ö†Ô∏è Multi-tenant v2.0 | ‚ùå Non |
| **Complexit√© install** | `pip install mem0ai` | Docker + Redis + config | Requiert RL training |
| **VRAM overhead** | Minimal (~350 Mo avec embeddings) | Variable (MemReader-4B = 2.5 Go+) | Requiert fine-tune 7B |
| **Cas d'usage** | Agents locaux, simple-robuste | Enterprise, multi-session | Recherche |

### Feuille de route recommand√©e

**Phase 1 (maintenant) ‚Äî Stack pragmatique** :
```
Mem0 + qwen3-embedding:0.6b + Qdrant + Kuzu
```
- Installe et valide la m√©moire inter-agents
- Tes agents se souviennent de leur nom, de CVE, de sessions de sparring
- Co√ªt VRAM total m√©moire : ~350 Mo

**Phase 2 (quand OLith V1 fonctionne) ‚Äî √âvaluer MemOS** :
- MemOS v2.0 apporte Tool Memory (trajectoires d'outils) ‚Üí pertinent pour sparring
- KV-cache injection ‚Üí -94% latence ‚Üí sparring plus rapide
- Mais n√©cessite migration et test de compatibilit√© Ollama

**Phase 3 (futur) ‚Äî Memory-R1 / Mem-Œ±** :
- Quand/si des mod√®les pr√©-entra√Æn√©s RL pour m√©moire sont disponibles sur Ollama
- L'id√©e d'un agent qui *apprend* √† g√©rer sa m√©moire est le futur, mais pas encore plug-and-play

---

## 4. Configuration Finale Recommand√©e pour OLith

### Embeddings

```bash
# Remplace nomic-embed-text par qwen3-embedding
ollama pull qwen3-embedding:0.6b

# V√©rifie que √ßa fonctionne
curl http://localhost:11434/api/embed \
  -d '{"model": "qwen3-embedding:0.6b", "input": "CVE-2024-1234 buffer overflow"}'
```


### Configuration Mem0 mise √† jour

```python
from mem0 import Memory

config = {
    "llm": {
        "provider": "ollama",
        "config": {
            "model": "qwen3:1.7b",  # Hodolith pour extraction rapide
            "ollama_base_url": "http://localhost:11434"
        }
    },
    "embedder": {
        "provider": "ollama",
        "config": {
            "model": "qwen3-embedding:0.6b",  # ‚Üê NOUVEAU : #1 mondial
            "ollama_base_url": "http://localhost:11434"
        }
    },
    "vector_store": {
        "provider": "qdrant",
        "config": {
            "host": "localhost",
            "port": 6333,
            "collection_name": "olith_memories",
            "embedding_model_dims": 1024,  # ‚Üê CHANG√â : 1024 par d√©faut Qwen3
            "distance": "cosine"
        }
    },
    "graph_store": {
        "provider": "kuzu",
        "config": {
            "url": "./olith_graph"
        }
    },
    "version": "v1.1"
}

memory = Memory.from_config(config_dict=config)
```

### Premier test : faire que tes agents se souviennent

```python
# √âtape 1 : Apprendre les identit√©s des agents
memory.add(
    "Je suis Hodolith, le dispatcher du syst√®me OLith. Mon r√¥le est de router les requ√™tes.",
    agent_id="hodolith",
    metadata={"type": "identity", "priority": "critical"}
)

memory.add(
    "Je suis Monolith, l'orchestrateur principal d'OLith bas√© sur Qwen3-14B.",
    agent_id="monolith",
    metadata={"type": "identity", "priority": "critical"}
)

memory.add(
    "Je suis Pyrolith, l'agent offensif d'OLith sp√©cialis√© en pentest et red team.",
    agent_id="pyrolith",
    metadata={"type": "identity", "priority": "critical"}
)

memory.add(
    "Je suis Cryolith, l'analyste d√©fensif d'OLith sp√©cialis√© en blue team et CVE.",
    agent_id="cryolith",
    metadata={"type": "identity", "priority": "critical"}
)

# √âtape 2 : V√©rifier la r√©cup√©ration
result = memory.search("Quel est mon nom et mon r√¥le ?", agent_id="pyrolith")
print(result)
# ‚Üí Devrait retourner l'identit√© de Pyrolith
```

### Budget VRAM r√©vis√© avec qwen3-embedding:0.6b

| Composant | VRAM |
|-----------|------|
| qwen3-embedding:0.6b (embeddings) | ~350 Mo |
| Qdrant (Docker, CPU) | 0 Mo VRAM |
| Kuzu (embedded, CPU) | 0 Mo VRAM |
| Mem0 (Python, CPU) | 0 Mo VRAM |
| **Total m√©moire stack** | **~350 Mo** |
| Agent actif (ex: Qwen3-14B) | ~10-11 Go |
| **Total avec 1 agent** | **~11 Go / 16 Go VRAM** |

---

## 5. R√©sum√© des D√©couvertes

### Sur les embeddings :
- **Snowflake Arctic Embed 2** √©tait un bon choix en 2024, mais il est d√©pass√© en 2025
- **Qwen3-Embedding** est le #1 mondial MTEB Multilingual (score 70.58)
- La version 0.6B suffit pour OLith : qualit√© sup√©rieure, code-aware, instruction-aware, 32K contexte
- M√™me famille que tes agents ‚Üí coh√©rence s√©mantique maximale

### Sur les syst√®mes de m√©moire :
- **MemOS** (Shanghai Jiao Tong) a r√©volutionn√© le concept de m√©moire agent avec MemCubes (+159% vs OpenAI, +38.9% vs baselines)
- **MemoryOS** (EMNLP 2025, Beijing) a propos√© une hi√©rarchie short/mid/long-term (+48% F1)
- **Memory-R1** a prouv√© que le RL peut apprendre √† g√©rer la m√©moire (+57% vs Mem0)
- **Mem-Œ±** √©tend √ßa aux architectures m√©moire complexes

### Pour OLith V1 :
- **Mem0 + Qdrant + Kuzu reste le choix pragmatique** : mature, Ollama-natif, z√©ro infrastructure
- **Migrer vers `qwen3-embedding:0.6b`** au lieu de Snowflake ou nomic-embed-text
- **MemOS est l'avenir** mais n√©cessite plus de maturit√© pour remplacer Mem0 sur un setup local
- Les dimensions d'embedding passent de 768 (nomic) √† **1024** (qwen3) ‚Üí recr√©er la collection Qdrant

---

*Document g√©n√©r√© le 7 f√©vrier 2026 ‚Äî Recherche OLith*
